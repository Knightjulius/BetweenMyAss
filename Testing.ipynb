{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ඞ\n"
     ]
    }
   ],
   "source": [
    "print(chr(sum(range(ord(min(str(not())))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import tarfile\n",
    "import requests\n",
    "import random\n",
    "import matplotlib as plt\n",
    "from collections import Counter\n",
    "import os\n",
    "import pandas as pd\n",
    "# Set the seed for reproducibility\n",
    "seed_value = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Networks used by old paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read .mtx files (both weighted and unweighted) and create a graph\n",
    "def read_mtx_file(file_path, weighted=True):\n",
    "    G = nx.Graph()  # or nx.DiGraph() if the graph is directed\n",
    "    \n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "    # Skip header lines that start with '%%' (Matrix Market metadata)\n",
    "    matrix_data = [line for line in lines if not line.startswith('%%') and line.strip()]\n",
    "    \n",
    "    # Read the edges from the matrix data and add them to the graph\n",
    "    for line in matrix_data:\n",
    "        try:\n",
    "            # Split the line into components\n",
    "            parts = line.split()\n",
    "            u, v = int(parts[0]), int(parts[1])  # Convert nodes to integers\n",
    "            \n",
    "            if weighted:\n",
    "                # If the graph is weighted, assume the third element is the weight\n",
    "                weight = float(parts[2])\n",
    "                G.add_edge(u, v, weight=weight)\n",
    "            else:\n",
    "                # If unweighted, just add the edge without weight\n",
    "                G.add_edge(u, v)\n",
    "        except ValueError:\n",
    "            print(f\"Skipping invalid line: {line.strip()}\")\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistics(G):\n",
    "    print(f'Number of nodes: {G.number_of_nodes()}')\n",
    "    print(f'Number of edges: {G.number_of_edges()}')\n",
    "\n",
    "    # Density\n",
    "    density = nx.density(G)\n",
    "    print(\"The density of the graph is: \",density)\n",
    "\n",
    "    # average clustering coefficient\n",
    "    # Calculate the local clustering coefficient for each node\n",
    "    CC = nx.clustering(G)\n",
    "    # Calculate the average clustering coefficient\n",
    "    ACC = sum(CC.values()) / len(CC)\n",
    "    print(f\"Average Clustering Coefficient is: {ACC}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate betweenness centrality and save to a folder\n",
    "def calculate_and_save_betweenness(G, graph_name, output_folder='BetweennessCentrality'):\n",
    "    # Calculate betweenness centrality\n",
    "    betweenness = nx.betweenness_centrality(G)\n",
    "    \n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # Create a unique file name based on the graph name\n",
    "    file_path = os.path.join(output_folder, f'betweenness_centrality_{graph_name}.txt')\n",
    "    \n",
    "    # Save betweenness centrality to a text file\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(\"Node\\tBetweennessCentrality\\n\")  # Write header\n",
    "        for node, centrality in betweenness.items():\n",
    "            f.write(f\"{node}\\t{centrality}\\n\")\n",
    "    \n",
    "    print(f\"Betweenness centrality saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for Erdos-Renyi graph\n",
    "n = 2000  # Number of vertices\n",
    "m = 7980  # Number of edges\n",
    "\n",
    "# Generate Erdos-Renyi random graph\n",
    "G = nx.gnm_random_graph(n, m, seed=seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 2000\n",
      "Number of edges: 7980\n",
      "The density of the graph is:  0.003991995997998999\n",
      "Average Clustering Coefficient is: 0.004036149879532232\n"
     ]
    }
   ],
   "source": [
    "statistics(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcalculate_and_save_betweenness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRand\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 4\u001b[0m, in \u001b[0;36mcalculate_and_save_betweenness\u001b[1;34m(G, graph_name, output_folder)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_and_save_betweenness\u001b[39m(G, graph_name, output_folder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBetweennessCentrality\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# Calculate betweenness centrality\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     betweenness \u001b[38;5;241m=\u001b[39m \u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbetweenness_centrality\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Create the output folder if it doesn't exist\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(output_folder):\n",
      "File \u001b[1;32mc:\\Users\\Juliu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\networkx\\utils\\decorators.py:770\u001b[0m, in \u001b[0;36margmap.__call__.<locals>.func\u001b[1;34m(_argmap__wrapper, *args, **kwargs)\u001b[0m\n\u001b[0;32m    769\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(\u001b[38;5;241m*\u001b[39margs, __wrapper\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 770\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m argmap\u001b[38;5;241m.\u001b[39m_lazy_compile(__wrapper)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m<class 'networkx.utils.decorators.argmap'> compilation 12:4\u001b[0m, in \u001b[0;36margmap_betweenness_centrality_9\u001b[1;34m(G, k, normalized, weight, endpoints, seed, backend, **backend_kwargs)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgzip\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Juliu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\networkx\\utils\\backends.py:412\u001b[0m, in \u001b[0;36m_dispatch.__call__\u001b[1;34m(self, backend, *args, **kwargs)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m backends:\n\u001b[0;32m    411\u001b[0m         \u001b[38;5;66;03m# Fast path if no backends are installed\u001b[39;00m\n\u001b[1;32m--> 412\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    414\u001b[0m     \u001b[38;5;66;03m# Use `backend_name` in this function instead of `backend`\u001b[39;00m\n\u001b[0;32m    415\u001b[0m     backend_name \u001b[38;5;241m=\u001b[39m backend\n",
      "File \u001b[1;32mc:\\Users\\Juliu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\networkx\\algorithms\\centrality\\betweenness.py:136\u001b[0m, in \u001b[0;36mbetweenness_centrality\u001b[1;34m(G, k, normalized, weight, endpoints, seed)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m nodes:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;66;03m# single source shortest paths\u001b[39;00m\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# use BFS\u001b[39;00m\n\u001b[1;32m--> 136\u001b[0m         S, P, sigma, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_single_source_shortest_path_basic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# use Dijkstra's algorithm\u001b[39;00m\n\u001b[0;32m    138\u001b[0m         S, P, sigma, _ \u001b[38;5;241m=\u001b[39m _single_source_dijkstra_path_basic(G, s, weight)\n",
      "File \u001b[1;32mc:\\Users\\Juliu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\networkx\\algorithms\\centrality\\betweenness.py:259\u001b[0m, in \u001b[0;36m_single_source_shortest_path_basic\u001b[1;34m(G, s)\u001b[0m\n\u001b[0;32m    257\u001b[0m P \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m G:\n\u001b[1;32m--> 259\u001b[0m     \u001b[43mP\u001b[49m\u001b[43m[\u001b[49m\u001b[43mv\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    260\u001b[0m sigma \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m\u001b[38;5;241m.\u001b[39mfromkeys(G, \u001b[38;5;241m0.0\u001b[39m)  \u001b[38;5;66;03m# sigma[v]=0 for v in G\u001b[39;00m\n\u001b[0;32m    261\u001b[0m D \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "calculate_and_save_betweenness(G, 'Rand')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pref-attach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pref-attach\n",
    "# Parameters: number of nodes (2000) and edges to attach per new node \n",
    "n_nodes = 2000  # number of nodes\n",
    "# needs an into so the num of edges cant be 7980 exactly\n",
    "m_edges = 4     # number of edges to attach per new node\n",
    "\n",
    "# Generate the graph using the Preferential Attachment model\n",
    "G = nx.barabasi_albert_graph(n_nodes, m_edges, seed=seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 2000\n",
      "Number of edges: 7984\n",
      "The density of the graph is:  0.00399399699849925\n",
      "Average Clustering Coefficient is: 0.019885923481658265\n"
     ]
    }
   ],
   "source": [
    "statistics(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Betweenness centrality saved to BetweennessCentrality\\betweenness_centrality_Pref-attach.txt\n"
     ]
    }
   ],
   "source": [
    "calculate_and_save_betweenness(G, 'Pref-attach')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bio-pin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO import bio pin als ie bestaat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crawl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: Run only once and edit the header of the file\n",
    "\n",
    "# Extract the contents of the tar.gz file\n",
    "with tarfile.open('OriginalGraphs/wb-cs-stanford.tar.gz', 'r:gz') as tar:\n",
    "    tar.extractall(path='output_directory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the graph\n",
    "file_path = 'output_directory/wb-cs-stanford/wb-cs-stanford.mtx'\n",
    "G = read_mtx_file(file_path, weighted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 9435\n",
      "Number of edges: 28726\n",
      "The density of the graph is:  0.0006454570896077836\n",
      "Average Clustering Coefficient is: 0.37014259070785793\n"
     ]
    }
   ],
   "source": [
    "statistics(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Betweenness centrality saved to BetweennessCentrality\\betweenness_centrality_Crawl.txt\n"
     ]
    }
   ],
   "source": [
    "calculate_and_save_betweenness(G, 'Crawl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: Run only once and edit the header of the file\n",
    "\n",
    "# Extract the contents of the tar.gz file\n",
    "with tarfile.open('OriginalGraphs/lederberg.tar.gz', 'r:gz') as tar:\n",
    "    tar.extractall(path='output_directory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping invalid line: %-------------------------------------------------------------------------------\n",
      "Skipping invalid line: % UF Sparse Matrix Collection, Tim Davis\n",
      "Skipping invalid line: % http://www.cise.ufl.edu/research/sparse/matrices/Pajek/Lederberg\n",
      "Skipping invalid line: % name: Pajek/Lederberg\n",
      "Skipping invalid line: % [Pajek network: Lederberg citation network]\n",
      "Skipping invalid line: % id: 1508\n",
      "Skipping invalid line: % date: 2002\n",
      "Skipping invalid line: % author: E. Garfield\n",
      "Skipping invalid line: % ed: V. Batagelj\n",
      "Skipping invalid line: % fields: name title A id kind notes aux date author ed\n",
      "Skipping invalid line: % aux: pubyear gcs nodename\n",
      "Skipping invalid line: % kind: directed multigraph\n",
      "Skipping invalid line: %-------------------------------------------------------------------------------\n",
      "Skipping invalid line: % notes:\n",
      "Skipping invalid line: % ------------------------------------------------------------------------------\n",
      "Skipping invalid line: % Pajek network converted to sparse adjacency matrix for inclusion in UF sparse\n",
      "Skipping invalid line: % matrix collection, Tim Davis.  For Pajek datasets, See V. Batagelj & A. Mrvar,\n",
      "Skipping invalid line: % http://vlado.fmf.uni-lj.si/pub/networks/data/.\n",
      "Skipping invalid line: % ------------------------------------------------------------------------------\n",
      "Skipping invalid line: %  Articles by and citing J Lederberg, 1945-2002, Wed Jul 31 13:40:22 2002\n",
      "Skipping invalid line: %-------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Load the graph\n",
    "file_path = 'output_directory/Lederberg/Lederberg.mtx'\n",
    "G = read_mtx_file(file_path, weighted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 8324\n",
      "Number of edges: 41539\n",
      "The density of the graph is:  0.0011991515322344252\n",
      "Average Clustering Coefficient is: 0.31436910784645994\n"
     ]
    }
   ],
   "source": [
    "statistics(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Betweenness centrality saved to BetweennessCentrality\\betweenness_centrality_Cite.txt\n"
     ]
    }
   ],
   "source": [
    "calculate_and_save_betweenness(G, 'Cite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: Run only once and edit the header of the file\n",
    "url = \"http://www.diag.uniroma1.it/~challenge9/data/rome/rome99.gr\"\n",
    "response = requests.get(url)\n",
    "\n",
    "with open(\"rome99.gr\", \"wb\") as f:\n",
    "    f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path (replace with the actual path to your file)\n",
    "file_path = \"OriginalGraphs/rome99.gr\"\n",
    "\n",
    "# Create an empty graph (you can choose directed or undirected based on your dataset)\n",
    "G = nx.Graph()  # Use nx.DiGraph() for directed graphs\n",
    "\n",
    "# Open the file and read line by line\n",
    "with open(file_path, 'r') as f:\n",
    "    for line in f:\n",
    "        # Skip empty lines or comment lines\n",
    "        if line.strip() and not line.startswith(\"#\"):\n",
    "            parts = line.split()\n",
    "            \n",
    "            # Check if the line starts with a non-numeric character ('a') and remove it\n",
    "            if parts[0] == 'a':\n",
    "                parts = parts[1:]  # Remove the first part (non-numeric 'a')\n",
    "            \n",
    "            if len(parts) != 3:  # Ensure the line has exactly 3 parts\n",
    "                continue  # Skip malformed lines\n",
    "\n",
    "            try:\n",
    "                # Try to convert vertex1, vertex2 to integers and weight to a float\n",
    "                vertex1 = int(parts[0])\n",
    "                vertex2 = int(parts[1])\n",
    "                weight = float(parts[2])  # Adjust type if weights are integers\n",
    "                \n",
    "                # Add the edge to the graph\n",
    "                G.add_edge(vertex1, vertex2, weight=weight)\n",
    "            except ValueError:\n",
    "                # Skip lines where conversion fails (e.g., non-numeric data)\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 3353\n",
      "Number of edges: 4831\n",
      "The density of the graph is:  0.0008596654440471861\n",
      "Average Clustering Coefficient is: 0.03027139874739033\n"
     ]
    }
   ],
   "source": [
    "statistics(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Betweenness centrality saved to BetweennessCentrality\\betweenness_centrality_Road.txt\n"
     ]
    }
   ],
   "source": [
    "calculate_and_save_betweenness(G, 'Road')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 262111\n",
      "Number of edges: 899792\n",
      "The density of the graph is:  2.6194088195261075e-05\n",
      "Average Clustering Coefficient is: 0.419780014607673\n"
     ]
    }
   ],
   "source": [
    "# Load the graph from the gzipped file\n",
    "file_path = \"NewGraphs/amazon0302.txt.gz\"\n",
    "G = nx.read_edgelist(file_path)\n",
    "\n",
    "statistics(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# too big run on LIACS servers\n",
    "# calculate_and_save_betweenness(G, 'Amazon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bio-CE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 15229\n",
      "Number of edges: 245952\n",
      "The density of the graph is:  0.0021211242020364595\n",
      "Average Clustering Coefficient is: 0.21116502730743858\n"
     ]
    }
   ],
   "source": [
    "# Load the weighted graph from the edge list file\n",
    "file_path = \"NewGraphs/bio-CE-CX.edges\"\n",
    "G = nx.read_edgelist(file_path, nodetype=int, data=(('weight', float),))\n",
    "\n",
    "statistics(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# too big run on LIACS servers\n",
    "# calculate_and_save_betweenness(G, 'BIO-CE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Musea Facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 22470\n",
      "Number of edges: 171002\n",
      "The density of the graph is:  0.000677398715568023\n",
      "Average Clustering Coefficient is: 0.3597383824426942\n"
     ]
    }
   ],
   "source": [
    "# Load the graph from the CSV edge list file (assuming the file has two columns: source and target nodes)\n",
    "file_path = \"NewGraphs/musae_facebook_edges.csv\"\n",
    "G= nx.read_edgelist(file_path, delimiter=',', nodetype=int)\n",
    "\n",
    "statistics(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# too big run on LIACS servers\n",
    "# calculate_and_save_betweenness(G, 'MuseaFacebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wiki Vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 7115\n",
      "Number of edges: 100762\n",
      "The density of the graph is:  0.003981420144693063\n",
      "Average Clustering Coefficient is: 0.14089784589308738\n"
     ]
    }
   ],
   "source": [
    "# Load the graph from the gzipped file\n",
    "file_path = \"NewGraphs\\wiki-Vote.txt.gz\"\n",
    "G = nx.read_edgelist(file_path)\n",
    "\n",
    "statistics(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# too big run on LIACS servers\n",
    "# calculate_and_save_betweenness(G, 'WikiVote')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Betweenness Centrality Approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import networkx as nx\n",
    "\n",
    "def calculate_dependency(predecessors, num_paths, dependency, source, nodes_sorted):\n",
    "    for w in nodes_sorted:\n",
    "        for v in predecessors[w]:\n",
    "            # λ_sv / λ_sw * (1 + δ_s*(w))\n",
    "            fraction = num_paths[v] / num_paths[w]\n",
    "            dependency[v] += fraction * (1 + dependency[w])\n",
    "        if w != source:\n",
    "            dependency[w] += 0  # Dependency is not propagated to the source\n",
    "    return dependency\n",
    "\n",
    "def shortest_path_computation(shortest_paths,G, s, node_list):\n",
    "    # shortest_paths = dict with dicts 1:[1:[1], 2:[1,2], 3:[1,2,3]]\n",
    "    # for all nodes check if the shortest paths from s to nodes are already there\n",
    "    # if not then add it to shortest paths to be computed\n",
    "    # then for each path\n",
    "    for node in node_list:\n",
    "        if \n",
    "\n",
    "\n",
    "\n",
    "def approximate_BC(G, v, c):\n",
    "    #step 1\n",
    "    sum = 0 \n",
    "    #step 2\n",
    "    k = 0 \n",
    "    #step 3\n",
    "    n = G.number_of_nodes()\n",
    "    while sum < c * n:\n",
    "        #step 4\n",
    "        s = random.choice(list(G.nodes))\n",
    "        #step 5\n",
    "        shortest_paths = nx.single_source_shortest_path_length(G, s)\n",
    "        #step 6\n",
    "        lambda_sw = {node: 0 for node in G.nodes} \n",
    "        lambda_sw[s] = 1\n",
    "        predecessors = {node: [] for node in G.nodes}  # P_s(w)\n",
    "\n",
    "        for node, dist in sorted(shortest_paths.items(), key=lambda x: x[1]):\n",
    "            for neighbor in G.neighbors(node):\n",
    "                if shortest_paths.get(neighbor, float('inf')) == dist - 1:\n",
    "                    lambda_sw[node] += lambda_sw[neighbor]\n",
    "                    predecessors[node].append(neighbor)\n",
    "\n",
    "        # fill dependency dictionary\n",
    "        dependency = {node: 0 for node in G.nodes}\n",
    "        nodes_sorted = sorted(shortest_paths, key=shortest_paths.get, reverse=True)\n",
    "        dependency = calculate_dependency(predecessors, lambda_sw, dependency, s, nodes_sorted)\n",
    "\n",
    "        #step 7\n",
    "        if v in dependency:\n",
    "            sum += dependency[v]\n",
    "        #step 8\n",
    "        k += 1\n",
    "\n",
    "    return sum * n / k if k > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_betweenness_centrality(G, target_node, c, file_path):\n",
    "    # Load the file into a DataFrame\n",
    "    df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "    # Get the true Betweenness Centrality from the file\n",
    "    true_row = df[df['Node'] == target_node]\n",
    "\n",
    "    if not true_row.empty:\n",
    "        true_centrality = true_row['BetweennessCentrality'].values[0]\n",
    "        print(f\"True Betweenness Centrality for node {target_node}: {true_centrality}\")\n",
    "\n",
    "        # Estimate the approximate Betweenness Centrality using your function\n",
    "        approx_centrality = approximate_BC(G, target_node, c)  # Replace G with your graph\n",
    "        print(f\"Approximate Betweenness Centrality for node {target_node}: {approx_centrality}\")\n",
    "\n",
    "        # Calculate and print the difference between the true and approximate values\n",
    "        difference = abs(true_centrality - approx_centrality)\n",
    "        print(f\"Difference between true and approximate Betweenness Centrality: {difference}\")\n",
    "    else:\n",
    "        print(f\"target_node {target_node} not found in the file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Betweenness Centrality for node 5: 0.0009817626772543\n",
      "Approximate Betweenness Centrality for node 5: 8516.3273117537\n",
      "Difference between true and approximate Betweenness Centrality: 8516.326329991021\n"
     ]
    }
   ],
   "source": [
    "# Parameters for Erdos-Renyi graph\n",
    "n = 2000  # Number of vertices\n",
    "m = 7980  # Number of edges\n",
    "\n",
    "# Generate Erdos-Renyi random graph\n",
    "G = nx.gnm_random_graph(n, m, seed=seed_value)\n",
    "\n",
    "compare_betweenness_centrality(G, target_node=5, c=10, file_path=\"BetweennessCentrality/betweenness_centrality_Rand.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
