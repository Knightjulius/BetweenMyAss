{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ඞ\n"
     ]
    }
   ],
   "source": [
    "print(chr(sum(range(ord(min(str(not())))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import tarfile\n",
    "import requests\n",
    "import random\n",
    "import matplotlib as plt\n",
    "from collections import Counter\n",
    "import os\n",
    "# Set the seed for reproducibility\n",
    "seed_value = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Networks used by old paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read .mtx files (both weighted and unweighted) and create a graph\n",
    "def read_mtx_file(file_path, weighted=True):\n",
    "    G = nx.Graph()  # or nx.DiGraph() if the graph is directed\n",
    "    \n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "    # Skip header lines that start with '%%' (Matrix Market metadata)\n",
    "    matrix_data = [line for line in lines if not line.startswith('%%') and line.strip()]\n",
    "    \n",
    "    # Read the edges from the matrix data and add them to the graph\n",
    "    for line in matrix_data:\n",
    "        try:\n",
    "            # Split the line into components\n",
    "            parts = line.split()\n",
    "            u, v = int(parts[0]), int(parts[1])  # Convert nodes to integers\n",
    "            \n",
    "            if weighted:\n",
    "                # If the graph is weighted, assume the third element is the weight\n",
    "                weight = float(parts[2])\n",
    "                G.add_edge(u, v, weight=weight)\n",
    "            else:\n",
    "                # If unweighted, just add the edge without weight\n",
    "                G.add_edge(u, v)\n",
    "        except ValueError:\n",
    "            print(f\"Skipping invalid line: {line.strip()}\")\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistics(G):\n",
    "    print(f'Number of nodes: {G.number_of_nodes()}')\n",
    "    print(f'Number of edges: {G.number_of_edges()}')\n",
    "\n",
    "    # Density\n",
    "    density = nx.density(G)\n",
    "    print(\"The density of the graph is: \",density)\n",
    "\n",
    "    # average clustering coefficient\n",
    "    # Calculate the local clustering coefficient for each node\n",
    "    CC = nx.clustering(G)\n",
    "    # Calculate the average clustering coefficient\n",
    "    ACC = sum(CC.values()) / len(CC)\n",
    "    print(f\"Average Clustering Coefficient is: {ACC}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate betweenness centrality and save to a folder\n",
    "def calculate_and_save_betweenness(G, graph_name, output_folder='BetweennessCentrality'):\n",
    "    # Calculate betweenness centrality\n",
    "    betweenness = nx.betweenness_centrality(G)\n",
    "    \n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # Create a unique file name based on the graph name\n",
    "    file_path = os.path.join(output_folder, f'betweenness_centrality_{graph_name}.txt')\n",
    "    \n",
    "    # Save betweenness centrality to a text file\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(\"Node\\tBetweennessCentrality\\n\")  # Write header\n",
    "        for node, centrality in betweenness.items():\n",
    "            f.write(f\"{node}\\t{centrality}\\n\")\n",
    "    \n",
    "    print(f\"Betweenness centrality saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for Erdos-Renyi graph\n",
    "n = 2000  # Number of vertices\n",
    "m = 7980  # Number of edges\n",
    "\n",
    "# Generate Erdos-Renyi random graph\n",
    "G = nx.gnm_random_graph(n, m, seed=seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 2000\n",
      "Number of edges: 7980\n",
      "The density of the graph is:  0.003991995997998999\n",
      "Average Clustering Coefficient is: 0.004036149879532232\n"
     ]
    }
   ],
   "source": [
    "statistics(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Betweenness centrality saved to BetweennessCentrality\\betweenness_centrality_Rand.txt\n"
     ]
    }
   ],
   "source": [
    "calculate_and_save_betweenness(G, 'Rand')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pref-attach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pref-attach\n",
    "# Parameters: number of nodes (2000) and edges to attach per new node \n",
    "n_nodes = 2000  # number of nodes\n",
    "# needs an into so the num of edges cant be 7980 exactly\n",
    "m_edges = 4     # number of edges to attach per new node\n",
    "\n",
    "# Generate the graph using the Preferential Attachment model\n",
    "G = nx.barabasi_albert_graph(n_nodes, m_edges, seed=seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 2000\n",
      "Number of edges: 7984\n",
      "The density of the graph is:  0.00399399699849925\n",
      "Average Clustering Coefficient is: 0.019885923481658265\n"
     ]
    }
   ],
   "source": [
    "statistics(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Betweenness centrality saved to BetweennessCentrality\\betweenness_centrality_Pref-attach.txt\n"
     ]
    }
   ],
   "source": [
    "calculate_and_save_betweenness(G, 'Pref-attach')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bio-pin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO import bio pin als ie bestaat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crawl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: Run only once and edit the header of the file\n",
    "\n",
    "# Extract the contents of the tar.gz file\n",
    "with tarfile.open('OriginalGraphs/wb-cs-stanford.tar.gz', 'r:gz') as tar:\n",
    "    tar.extractall(path='output_directory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the graph\n",
    "file_path = 'output_directory/wb-cs-stanford/wb-cs-stanford.mtx'\n",
    "G = read_mtx_file(file_path, weighted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 9435\n",
      "Number of edges: 28726\n",
      "The density of the graph is:  0.0006454570896077836\n",
      "Average Clustering Coefficient is: 0.37014259070785793\n"
     ]
    }
   ],
   "source": [
    "statistics(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Betweenness centrality saved to BetweennessCentrality\\betweenness_centrality_Crawl.txt\n"
     ]
    }
   ],
   "source": [
    "calculate_and_save_betweenness(G, 'Crawl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: Run only once and edit the header of the file\n",
    "\n",
    "# Extract the contents of the tar.gz file\n",
    "with tarfile.open('OriginalGraphs/lederberg.tar.gz', 'r:gz') as tar:\n",
    "    tar.extractall(path='output_directory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping invalid line: %-------------------------------------------------------------------------------\n",
      "Skipping invalid line: % UF Sparse Matrix Collection, Tim Davis\n",
      "Skipping invalid line: % http://www.cise.ufl.edu/research/sparse/matrices/Pajek/Lederberg\n",
      "Skipping invalid line: % name: Pajek/Lederberg\n",
      "Skipping invalid line: % [Pajek network: Lederberg citation network]\n",
      "Skipping invalid line: % id: 1508\n",
      "Skipping invalid line: % date: 2002\n",
      "Skipping invalid line: % author: E. Garfield\n",
      "Skipping invalid line: % ed: V. Batagelj\n",
      "Skipping invalid line: % fields: name title A id kind notes aux date author ed\n",
      "Skipping invalid line: % aux: pubyear gcs nodename\n",
      "Skipping invalid line: % kind: directed multigraph\n",
      "Skipping invalid line: %-------------------------------------------------------------------------------\n",
      "Skipping invalid line: % notes:\n",
      "Skipping invalid line: % ------------------------------------------------------------------------------\n",
      "Skipping invalid line: % Pajek network converted to sparse adjacency matrix for inclusion in UF sparse\n",
      "Skipping invalid line: % matrix collection, Tim Davis.  For Pajek datasets, See V. Batagelj & A. Mrvar,\n",
      "Skipping invalid line: % http://vlado.fmf.uni-lj.si/pub/networks/data/.\n",
      "Skipping invalid line: % ------------------------------------------------------------------------------\n",
      "Skipping invalid line: %  Articles by and citing J Lederberg, 1945-2002, Wed Jul 31 13:40:22 2002\n",
      "Skipping invalid line: %-------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Load the graph\n",
    "file_path = 'output_directory/Lederberg/Lederberg.mtx'\n",
    "G = read_mtx_file(file_path, weighted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 8324\n",
      "Number of edges: 41539\n",
      "The density of the graph is:  0.0011991515322344252\n",
      "Average Clustering Coefficient is: 0.31436910784645994\n"
     ]
    }
   ],
   "source": [
    "statistics(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Betweenness centrality saved to BetweennessCentrality\\betweenness_centrality_Cite.txt\n"
     ]
    }
   ],
   "source": [
    "calculate_and_save_betweenness(G, 'Cite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: Run only once and edit the header of the file\n",
    "url = \"http://www.diag.uniroma1.it/~challenge9/data/rome/rome99.gr\"\n",
    "response = requests.get(url)\n",
    "\n",
    "with open(\"rome99.gr\", \"wb\") as f:\n",
    "    f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path (replace with the actual path to your file)\n",
    "file_path = \"OriginalGraphs/rome99.gr\"\n",
    "\n",
    "# Create an empty graph (you can choose directed or undirected based on your dataset)\n",
    "G = nx.Graph()  # Use nx.DiGraph() for directed graphs\n",
    "\n",
    "# Open the file and read line by line\n",
    "with open(file_path, 'r') as f:\n",
    "    for line in f:\n",
    "        # Skip empty lines or comment lines\n",
    "        if line.strip() and not line.startswith(\"#\"):\n",
    "            parts = line.split()\n",
    "            \n",
    "            # Check if the line starts with a non-numeric character ('a') and remove it\n",
    "            if parts[0] == 'a':\n",
    "                parts = parts[1:]  # Remove the first part (non-numeric 'a')\n",
    "            \n",
    "            if len(parts) != 3:  # Ensure the line has exactly 3 parts\n",
    "                continue  # Skip malformed lines\n",
    "\n",
    "            try:\n",
    "                # Try to convert vertex1, vertex2 to integers and weight to a float\n",
    "                vertex1 = int(parts[0])\n",
    "                vertex2 = int(parts[1])\n",
    "                weight = float(parts[2])  # Adjust type if weights are integers\n",
    "                \n",
    "                # Add the edge to the graph\n",
    "                G.add_edge(vertex1, vertex2, weight=weight)\n",
    "            except ValueError:\n",
    "                # Skip lines where conversion fails (e.g., non-numeric data)\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 3353\n",
      "Number of edges: 4831\n",
      "The density of the graph is:  0.0008596654440471861\n",
      "Average Clustering Coefficient is: 0.03027139874739033\n"
     ]
    }
   ],
   "source": [
    "statistics(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Betweenness centrality saved to BetweennessCentrality\\betweenness_centrality_Road.txt\n"
     ]
    }
   ],
   "source": [
    "calculate_and_save_betweenness(G, 'Road')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 262111\n",
      "Number of edges: 899792\n",
      "The density of the graph is:  2.6194088195261075e-05\n",
      "Average Clustering Coefficient is: 0.419780014607673\n"
     ]
    }
   ],
   "source": [
    "# Load the graph from the gzipped file\n",
    "file_path = \"NewGraphs/amazon0302.txt.gz\"\n",
    "G = nx.read_edgelist(file_path)\n",
    "\n",
    "statistics(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# facking groot, run op LIACS servers lmao\n",
    "# calculate_and_save_betweenness(G, 'Amazon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bio-CE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 15229\n",
      "Number of edges: 245952\n",
      "The density of the graph is:  0.0021211242020364595\n",
      "Average Clustering Coefficient is: 0.21116502730743858\n"
     ]
    }
   ],
   "source": [
    "# Load the weighted graph from the edge list file\n",
    "file_path = \"NewGraphs/bio-CE-CX.edges\"\n",
    "G = nx.read_edgelist(file_path, nodetype=int, data=(('weight', float),))\n",
    "\n",
    "statistics(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# facking groot, run op LIACS servers lmao\n",
    "# calculate_and_save_betweenness(G, 'BIO-CE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Musea Facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 22470\n",
      "Number of edges: 171002\n",
      "The density of the graph is:  0.000677398715568023\n",
      "Average Clustering Coefficient is: 0.3597383824426942\n"
     ]
    }
   ],
   "source": [
    "# Load the graph from the CSV edge list file (assuming the file has two columns: source and target nodes)\n",
    "file_path = \"NewGraphs/musae_facebook_edges.csv\"\n",
    "G= nx.read_edgelist(file_path, delimiter=',', nodetype=int)\n",
    "\n",
    "statistics(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# facking groot, run op LIACS servers lmao\n",
    "# calculate_and_save_betweenness(G, 'MuseaFacebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wiki Vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 7115\n",
      "Number of edges: 100762\n",
      "The density of the graph is:  0.003981420144693063\n",
      "Average Clustering Coefficient is: 0.14089784589308738\n"
     ]
    }
   ],
   "source": [
    "# Load the graph from the gzipped file\n",
    "file_path = \"NewGraphs\\wiki-Vote.txt.gz\"\n",
    "G = nx.read_edgelist(file_path)\n",
    "\n",
    "statistics(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# facking groot, run op LIACS servers lmao\n",
    "# calculate_and_save_betweenness(G, 'WikiVote')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Betweenness Centrality Approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dependency(predecessors, num_paths, dependency, source, nodes_sorted):\n",
    "    for w in nodes_sorted:\n",
    "        for v in predecessors[w]:\n",
    "            # λ_sv / λ_sw * (1 + δ_s*(w))\n",
    "            fraction = num_paths[v] / num_paths[w]\n",
    "            dependency[v] += fraction * (1 + dependency[w])\n",
    "        if w != source:\n",
    "            dependency[w] += 0  # Dependency is not propagated to the source\n",
    "    return dependency\n",
    "\n",
    "def approximate_BC(G, v, c):\n",
    "    sum = 0\n",
    "    k = 0\n",
    "    n = G.number_of_nodes()\n",
    "    \n",
    "    while sum < c * n:\n",
    "        # Step 4: Randomly choose a source node s\n",
    "        s = random.choice(list(G.nodes))\n",
    "        \n",
    "        # Step 5: Calculate shortest paths from s\n",
    "        shortest_paths = nx.single_source_shortest_path_length(G, s)\n",
    "        \n",
    "        # Step 6: Initialize λ_sw and predecessors\n",
    "        lambda_sw = {node: 0 for node in G.nodes}\n",
    "        lambda_sw[s] = 1\n",
    "        predecessors = {node: [] for node in G.nodes}\n",
    "        \n",
    "        # Process nodes in increasing distance from s\n",
    "        for node, dist in sorted(shortest_paths.items(), key=lambda x: x[1]):\n",
    "            for neighbor in G.neighbors(node):\n",
    "                if shortest_paths.get(neighbor, float('inf')) == dist - 1:\n",
    "                    lambda_sw[node] += lambda_sw[neighbor]\n",
    "                    predecessors[node].append(neighbor)\n",
    "        \n",
    "        # Fill dependency dictionary\n",
    "        dependency = {node: 0 for node in G.nodes}\n",
    "        nodes_sorted = sorted(shortest_paths, key=shortest_paths.get, reverse=True)\n",
    "        dependency = calculate_dependency(predecessors, lambda_sw, dependency, s, nodes_sorted)\n",
    "        \n",
    "        # Step 7: Add to sum if v is in the dependency\n",
    "        if v in dependency:\n",
    "            sum += dependency[v]\n",
    "        \n",
    "        # Step 8: Increment the count of iterations\n",
    "        k += 1\n",
    "    \n",
    "    # Return the average betweenness centrality approximation\n",
    "    return sum * n / k if k > 0 else 0\n",
    "\n",
    "def calculate_and_save_approximate_BC(G, threshold, output_folder='C{threshold}_BetweenAprox'):\n",
    "    # Create the folder if it doesn't exist\n",
    "    output_folder = output_folder.format(threshold=threshold)\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # Calculate approximate BC for all nodes\n",
    "    approximate_bc_values = {}\n",
    "    for node in G.nodes:\n",
    "        approx_bc = approximate_BC(G, node, threshold)\n",
    "        approximate_bc_values[node] = approx_bc\n",
    "    \n",
    "    # Save the results to a file in the folder\n",
    "    file_path = os.path.join(output_folder, f'approximate_betweenness_centrality_c{threshold}.txt')\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(\"Node\\tApproximateBetweennessCentrality\\n\")  # Write header\n",
    "        for node, bc_value in approximate_bc_values.items():\n",
    "            f.write(f\"{node}\\t{bc_value}\\n\")\n",
    "    \n",
    "    print(f\"Approximate betweenness centrality saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m G \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mgnm_random_graph(n, m, seed\u001b[38;5;241m=\u001b[39mseed_value)\n\u001b[0;32m      8\u001b[0m threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m  \u001b[38;5;66;03m# Example threshold value\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[43mcalculate_and_save_approximate_BC\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[51], line 59\u001b[0m, in \u001b[0;36mcalculate_and_save_approximate_BC\u001b[1;34m(G, threshold, output_folder)\u001b[0m\n\u001b[0;32m     57\u001b[0m approximate_bc_values \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m G\u001b[38;5;241m.\u001b[39mnodes:\n\u001b[1;32m---> 59\u001b[0m     approx_bc \u001b[38;5;241m=\u001b[39m \u001b[43mapproximate_BC\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m     approximate_bc_values[node] \u001b[38;5;241m=\u001b[39m approx_bc\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Save the results to a file in the folder\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[51], line 31\u001b[0m, in \u001b[0;36mapproximate_BC\u001b[1;34m(G, v, c)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node, dist \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(shortest_paths\u001b[38;5;241m.\u001b[39mitems(), key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m neighbor \u001b[38;5;129;01min\u001b[39;00m G\u001b[38;5;241m.\u001b[39mneighbors(node):\n\u001b[1;32m---> 31\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m shortest_paths\u001b[38;5;241m.\u001b[39mget(neighbor, \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;241m==\u001b[39m dist \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     32\u001b[0m             lambda_sw[node] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m lambda_sw[neighbor]\n\u001b[0;32m     33\u001b[0m             predecessors[node]\u001b[38;5;241m.\u001b[39mappend(neighbor)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Parameters for Erdos-Renyi graph\n",
    "n = 2000  # Number of vertices\n",
    "m = 7980  # Number of edges\n",
    "\n",
    "# Generate Erdos-Renyi random graph\n",
    "G = nx.gnm_random_graph(n, m, seed=seed_value)\n",
    "\n",
    "threshold = 5  # Example threshold value\n",
    "calculate_and_save_approximate_BC(G, threshold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
